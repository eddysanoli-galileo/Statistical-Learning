{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ensayo SVM\n",
    "\n",
    "Debe ser agregado al proyecto en un notebook con descripción, texto, imágenes, etc en markdown y ejemplos en código:\n",
    "\n",
    "- hipótesis de SVM\n",
    "- función de costo\n",
    "- Algoritmo de aprendizaje/entrenamiento\n",
    "- Propiedades, similitudes, diferencias ,ventajas y desventajas sobre otros algoritmos y modelos.\n",
    "- Kernel-trick/basis functions\n",
    "\n",
    "Referencias útiles:\n",
    "- [Contenido SVM galileo(2020)](https://youtu.be/pdR9_eylib8?t=6134)\n",
    "- [Hands on Machine Learning with sklearn and tensorflow (capitulo 5)](https://github.com/yanshengjia/ml-road/blob/master/resources/Hands%20On%20Machine%20Learning%20with%20Scikit%20Learn%20and%20TensorFlow.pdf)\n",
    "- [Support vector machines(Stanford CS229 Machine Lerning 2018)](https://youtu.be/lDwow4aOrtg)\n",
    "- [Kernel trick](https://www.youtube.com/watch?v=vMmG_7JcfIc)\n",
    "\n",
    "Videos de estudiantes de años previos:\n",
    "- https://youtu.be/VWwb3IAB6Rc\n",
    "- https://youtu.be/envRLLZmio8\n",
    "\n",
    "\n",
    "------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Hipótesis de SVM\n",
    "\n",
    "La idea básica de un SVM (support vector machine) es la de crear una estructura similar a la de una red neuronal de pocas capas: Consiste en crear un hiperplano \"óptimo\" capaz de separar datos separables por fronteras lineales. Aquellos patrones que no son separables por fronteras lineales, entonces se pueden transformar a nuevos espacios dimensionales donde su separación sea mucho más sencilla. A la función empleada para realizar esta transformación se le denomina \"función kernel\". Pero, ¿qué es un support vector?\n",
    "\n",
    "Los support vectors consisten de los puntos de datos que están más cercanos a la frontera de decisión, en otras palabras, son los datos más difíciles de clasificar en un problema de esta índole debido a que son los más propensos a ser mal clasificados. Tomando esto en cuenta, se puede llegar a establecer que el hiperplano óptimo de separación es aquel que proviene de una función con el menor número posible de parámetros o variables con las que se debe de jugar para poder obtener una buena separación entre clases. \n",
    "\n",
    "En este sentido, un SVM maximiza el margen (la distancia del hiperplano a los support vectors) alrededor del hiperplano. Además, se puede probar que este es óptimo ya que este únicamente depende de un número pequeño de variable, en este caso, cada uno de los support vectors. \n",
    "\n",
    "![svm1](Media/svm1.PNG)\n",
    "\n",
    "## Función de Costo\n",
    "\n",
    "$$J(\\theta)=C \\sum_{i=1}^{m}\\left[y^{(i)} \\operatorname{cost}_{1}\\left(\\theta^{T} x^{(i)}\\right)+\\left(1-y^{(i)}\\right) \\operatorname{cost}_{0}\\left(\\theta^{T} x^{(i)}\\right)\\right]+\\frac{1}{2} \\sum_{i=1}^{n} \\theta_{i}^{2}$$\n",
    "\n",
    "Esta función de costo lo que consigue es minimizar el valor de $J(\\theta)$, lo cual asegura que el SVM sea lo más preciso posible.\n",
    "\n",
    "## Algoritmo de Aprendizaje Entrenamiento\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}